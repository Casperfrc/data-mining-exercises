{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(readapted from Toke Faurby and Chris Carvelli's)\n",
    "\n",
    "# Lab3 Classification and Regression\n",
    "\n",
    "The objective is to implement the core of the k-nn algorithm\n",
    "\n",
    "Schedule:\n",
    "* Classify data using k-neighbors\n",
    "* Use a confusion matrix to evaluate models\n",
    "\n",
    "## Reminder\n",
    "* [GitHub repo](https://github.com/Bhik95/data-mining-exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes matplotlib plots work better with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the necessary libraries. \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that data and data path is present\n",
    "basedir = \"./\"\n",
    "file = \"fifa.csv\"\n",
    "assert os.path.isdir(f\"{basedir}data\") and os.path.exists(f\"{basedir}data/{file}\"), 'Data not found. Make sure to have the most recent version!'\n",
    "\n",
    "data = pd.read_csv(f'{basedir}/data/fifa.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, height=5,hue=\"Position\").map(plt.scatter,\"SprintSpeed\",\"Agility\").add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, height=5,hue=\"Position\", col='Preferred Foot').map(plt.scatter,\"ShotPower\",'Penalties').add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plots shows that the `Position` of a player could be related to some of their statistics. The dataset contains 30+ statistics and we don't know which ones will be most helpful, so we are picking an arbitrary subset to avoid the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['Crossing','Finishing','HeadingAccuracy','ShortPassing','Volleys','Dribbling','Curve','FKAccuracy','LongPassing',\n",
    "            'BallControl','Acceleration','SprintSpeed','Agility','Reactions','Balance','ShotPower','Jumping','Stamina',\n",
    "            'Strength','LongShots','Aggression','Interceptions','Positioning','Vision','Penalties','Composure',\n",
    "            'Marking','StandingTackle','SlidingTackle','GKDiving','GKHandling','GKKicking','GKPositioning','GKReflexes']\n",
    "\n",
    "features = [\"SprintSpeed\",\"Agility\",\"ShotPower\",'Penalties']\n",
    "# cleaning: remove all the lines that contain a NaN in one of the feature columns\n",
    "data = data.dropna(subset=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem\n",
    "\n",
    "0. pick a value for K (number of clusters)\n",
    "1. split the data in train and validation set\n",
    "2. normalize fields\n",
    "3. foreach `datapoint` in `validation set`:\n",
    "  1. find the K nearest neighbors\n",
    "  2. set as label of `datapoint` the label that appears most between its neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: define K\n",
    "K = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the right K can be tricky. As usual, [stand on the shoulder of giants](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#Parameter_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1: let's start with calculating the Euclidean distance from a single datapoint to all the other\n",
    "\n",
    "# parameters:\n",
    "# 1) the single data entry to classify, x\n",
    "# 2) the name of the class columns, class_col (not used in this step)\n",
    "# 3) the training set, train_set\n",
    "\n",
    "#TODO: Implement the euclidian distance calculation between the datapoint x and each datapoint of the training set.\n",
    "# Tips: Look for these pandas functions: .sub, .pow, .sum(axis=?)\n",
    "euclidian_distance = lambda x, class_col, train_set: (\n",
    "                                # TODO: my code here\n",
    "                            )\n",
    "\n",
    "# the first row of the result should be 0, since we are calculating the distance between a point and itself\n",
    "# check pandas API for iloc[] if necessary\n",
    "euclidian_distance(data.iloc[0], 'Position', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3.2: to implement k-nn, we need the K closest neighbors. We'll get them with a pandas function (nsmallest),\n",
    "# for convenience and performance\n",
    "\n",
    "euclidian_distance_nsmallest_K = lambda x, class_col, train_set: \n",
    "                                # TODO: start from the code created in the previous cell and only select the smallest K distances with nsmallest\n",
    "                               )\n",
    "\n",
    "euclidian_distance_nsmallest_K(data.iloc[0], 'Position', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3: from here, we need the labels associated to this rows. The result is still referencing to our original dataset\n",
    "# (the left column is the index on the original dataset), so we can use iloc[] as before for this\n",
    "\n",
    "# let's also move everything we did up until now in a different function\n",
    "nearest_neighbors = lambda x, train_set: (train_set[features].sub(x[features])\n",
    "                               # TODO: same code as previous cell\n",
    "                               ).index # retrieve the indices (INDICES != POSITIONS!!!)\n",
    "\n",
    "\n",
    "knn_classification = lambda x, class_col, train_set: (\n",
    "    # IMPORTANT: .loc[] instead of .iloc[] (see next cells)\n",
    "    train_set.loc[nearest_neighbors(x, train_set)]\n",
    ")\n",
    "\n",
    "\n",
    "knn_classification(data.iloc[0], 'Position', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4: now that we have the neigbors, lets get their labels and select the one that appear more times\n",
    "nearest_neighbors = lambda x, train_set: (train_set[features].sub(x[features])\n",
    "                               # TODO: same code as previous cell\n",
    "                               ).index # retrieve the indices (INDICES != POSITIONS!!!)\n",
    "\n",
    "\n",
    "knn_classification = lambda x, class_col, train_set: (\n",
    "    # IMPORTANT: .loc[] instead of .iloc[] (see next cells)\n",
    "    train_set.loc[nearest_neighbors(x, train_set)]\n",
    "        [class_col]\n",
    "        .mode() # get the mode (the most frequent value)\n",
    ")\n",
    "\n",
    "# this time we are using a different datapoint, it will show us a problem\n",
    "knn_classification(data.iloc[6], 'Position', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loc[] vs iloc[]\n",
    "\n",
    "`iloc[]` and `loc[]` seem similar but actually they are QUITE different:\n",
    "- `loc[i]` returns the row with index `i`\n",
    "- `iloc[i]` returns the row in the `i`-th position\n",
    "\n",
    "When creating a dataset (unless directly specified), the index of a row is just in position, so both functions will return the same row. That doesn't hold true after manipulating the DataFrame (eg, cleaning, sorting, etc).\n",
    "\n",
    "The correct way to reference a dataset using the entries of a DataFrame `a` from the entries af another DataFrame `b` is:\n",
    "```\n",
    "a.loc[b.index]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5: some of the modes that we will calculate will return more than one value. This won't work,\n",
    "#      so we need to pick one of them. The best solution would be to assign a weight to each neighbor\n",
    "#      based on its distance (see lecture's slides), sum the weights grouped by label and pick the label\n",
    "#      with the highest score.\n",
    "\n",
    "nearest_neighbors = lambda x, train_set: (train_set[features].sub(x[features])\n",
    "                               # TODO: same code as previous cell\n",
    "                               ).index # retrieve the indices (INDICES != POSITIONS!!!)\n",
    "\n",
    "\n",
    "knn_classification = lambda x, class_col, train_set: (\n",
    "    # IMPORTANT: .loc[] instead of .iloc[] (see next cell)\n",
    "    train_set.loc[nearest_neighbors(x, train_set)]\n",
    "        [class_col]\n",
    "        .mode()[0]\n",
    ")\n",
    "\n",
    "\n",
    "knn_classification(data.iloc[6], 'Position', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dataset, class_col, random_state=None, frac=0.995):\n",
    "    # 1: random split. It's always a good idea (maybe the dataset is sorted, and so on).\n",
    "    # random_state that you to always get the same split (useful for testing). Check docs\n",
    "    train_set = data.sample(frac=frac, random_state=random_state)\n",
    "    valid_set = data.drop(train_set.index)\n",
    "\n",
    "    classified_set = valid_set\n",
    "    classified_set[f'Calculated {class_col}'] = valid_set.apply(\n",
    "        lambda x: knn_classification(x, class_col, train_set),\n",
    "        axis=1\n",
    "    )\n",
    "    return classified_set\n",
    "\n",
    "classified_position = classify(data, 'Position')[['Position', 'Calculated Position']]\n",
    "classified_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification with positive class\n",
    "In many cases, it's important to determine if a datapoint belongs or not to a certain class or not and the distribution is skewed (poisonus/not poisonus, cancer/not cancer, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get a warning, please ignore it, everything works fine and I could not figure out what's the problem :/\n",
    "\n",
    "K = 3\n",
    "\n",
    "data['Goalkeeper'] = data['Position'] == 'GK'\n",
    "\n",
    "classified_goalkeeper = classify(data, 'Goalkeeper', frac=0.99)[['Goalkeeper', 'Calculated Goalkeeper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_goalkeeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification evaluation\n",
    "\n",
    "1. generate confusion matrix\n",
    "2. evaluate the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_results(data, class_col, binary=False):\n",
    "    labels = data[class_col].unique()\n",
    "    #TODO: Calculate the confusion matrix (look at sklearn.metrics.confusion_matrix)\n",
    "    cm = \n",
    "\n",
    "    print_confusion_matrix(\n",
    "        cm,\n",
    "        labels\n",
    "    )\n",
    "    plt.show()  # wait for the render (otherwise it will print the graphs async, after the strings)\n",
    "    \n",
    "    if binary:\n",
    "        tn, fp, fn, tp = cm.ravel() # True Negatives, False Positives, False Negatives, True Positives\n",
    "\n",
    "        #TODO: Calculate the following metrics starting from tn, fp, fn and tp:\n",
    "        accuracy = \n",
    "        err_rate = \n",
    "        sensitiv = \n",
    "        specific = \n",
    "        precision = \n",
    "\n",
    "        print(cm.ravel())\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Error rate: {err_rate}')\n",
    "        print(f'Sensitivity: {sensitiv}')\n",
    "        print(f'Specificity: {specific}')\n",
    "        print(f'Precision: {specific}')\n",
    "    else:\n",
    "        diag = [cm[i][i] for i in range(len(cm))]        \n",
    "        rows = [sum(cm[i]) for i in range(len(cm))]\n",
    "        \n",
    "        right_pred = sum(diag)\n",
    "        wrong_pred = sum(rows)\n",
    "        \n",
    "        print(f'Precision: {right_pred / wrong_pred}')\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "print_results(classified_position, 'Position')\n",
    "print_results(classified_goalkeeper, 'Goalkeeper', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy seems high for the `Goalkeeper` class, but because the percentage of goalkeepers is low. In those cases, Sensitivity is a much better metric. Here will probably be very low because the metric are chosen arbitrarly. You can check the link above to see how to pick appropriate dimensions.\n",
    "\n",
    "Additionally, for skewed distributions:\n",
    "> A drawback of the basic \"majority voting\" classification occurs when the class distribution is skewed. That is, examples of a more frequent class tend to dominate the prediction of the new example, because they tend to be common among the k nearest neighbors due to their large number[[4]](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#cite_note-Coomans_Massart1982-4). One way to overcome this problem is to weight the classification, taking into account the distance from the test point to each of its k nearest neighbors. The class (or value, in regression problems) of each of the k nearest points is multiplied by a weight proportional to the inverse of the distance from that point to the test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
